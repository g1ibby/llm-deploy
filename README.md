# LLM deploy

## Overview

This Python tool provides a command-line interface for managing and interacting with models and instances in the Ollama environment. It leverages the Typer library for building the CLI and implements functionalities like listing, pulling, running, and removing models, as well as managing instances.

## Features

- **List Offers**: View available offers based on GPU memory.
- **Run Models**: Run a specific model with configurable GPU memory and disk space options.
- **List Instances**: Display currently running instances.
- **Model Management**: Pull and remove specific models from an instance.
- **Instance Management**: Create, remove, and display details of instances.
- **Logs Retrieval**: Fetch logs for a specific instance.

